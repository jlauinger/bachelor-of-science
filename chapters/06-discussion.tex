%% -----------------------------------------------------------------------------

\chapter{Discussion}\label{ch:Discussion}
\glsresetall % Resets all acronyms to not used

This chapter discusses the results of the evaluation, and their implications. The findings are finally compared to related research, and possible future work is proposed.


%% -----------------------------------------------------------------------------

\section{Computational Complexity}\label{sec:complexity}

In order to use the proposed sender detection algorithm, it must be feasible to do all necessary calculations in real-time. In this section, I present an analysis of the computational complexity of the different components.

Two main categories of tasks can be identified. First, the generation of reference signals to use for cross-correlation. This can be pre-computed before any collisions are received and is therefore less time-critical. Second, correlating time-domain samples with the reference signals and sorting to work out a guess which senders participated. This needs to be done for every analysed collision.\\

Based on the results from the experiments with scrambler initialization and the destination MAC address as described in sections \ref{sec:ex-scrambler} and \ref{sec:ex-destination}, the following factors scale up the amount of necessary reference signals:

\begin{itemize}
  \item MAC addresses on the network
  \item \glspl{MCS}
  \item Scrambler initizaliation values
\end{itemize}

The destination MAC address can be ignored. This means that the algorithm scales according to the following equation:

$$ N_{RS} = N_{MAC} \cdot N_{MCS} \cdot N_{SI} = N_{MAC} \cdot 8 \cdot 127 $$\vspace{0cm}

Here, $ N_{RS} $ denotes the number of modulated reference signals, $ N_{MCS} $ is the number of available \glspl{MCS}, and $ N_{SI} $ describes the amount of possible scrambler initialization values.

Let $ n = N_{MAC} $ be the number of cached MAC addresses on the network. The worst-case asymmetric complexity in this case is:

$$ O("Sender ~Detection") = O(n \cdot 8 \cdot 127) = O(1016 n) = O(n) $$\vspace{0cm}

The algorithm scales linearly with the amount of stations on the IEEE 802.11 network. This is optimal since every station is a possible sender which has to be considered when decoding a collision. It is however debatable whether the linear factor of 1016 is feasible on commodity computing hardware. This would be necessary to enable broad usage of the detection technique as mentioned in chapter \ref{ch:introduction}. This is a quantitive analysis.\\

I used the Matlab profiler to gather data on the execution speeds of different parts of the algorithm. These measurements were done on a consumer laptop, featuring 2-core 3rd-generation Intel processor with Hyper-Threading at 1.9 GHz. The results are summarized in table \ref{tbl:timing}.

\begin{table}[ht]
	\centering
	\begin{tabular}{|p{8.5cm}|p{2.5cm}|}
		\hline
		\textbf{Function} & \textbf{Time Spent} \\ \hline
    wlanNonHTData & 241 ms \\ \hline
    CRC Calculation & 90 ms \\ \hline
		xcorr & 1 ms \\ \hline
	\end{tabular}
	\caption{Timing Analysis of the Detecting Algorithm \label{tbl:timing}}
\end{table}

This data suggests that the real-time part of the algorithm, which is limited to cross-correlation with \texttt{xcorr} is negligable when compared to the pre-modulation of reference signals. For small networks, the correlation time is probably fast enough. For high amount of stations however, the complexity gets out of hand quite quickly. For a network with 500 client for example, each collision requires a calculating of about 500 seconds. However, it is easily possible to parallelize this workload, or even use specialized hardware such as \glspl{FPGA}. In the extreme case, where every correlation is done at the same time, only 1 ms is needed for decoding the collision.

The calculating of CRC checksums is time-consuming, however not needed for the algorithm. Instead, dummy checksums can be used as descibed in section \ref{sec:matlab-impl}. Therefore, modulation of reference signals scales with the performance of the \texttt{wlanNonHTData} function.

Since the modulation of reference signals can be done ahead of time, the only important case is that of a newly connected client. In this case, 1016 new signals must be created for this new MAC address, which takes about 5 minutes without any parallelization. With more CPU cores however, this seems manageable.


%% -----------------------------------------------------------------------------

\section{Detection Quality}\label{sec:detection-quality}


%% -----------------------------------------------------------------------------

\section{IEEE 802.11 n/ac/ax networks}\label{sec:mimo}

This thesis only covered sender detection for IEEE 802.11 a/g networks. However, such networks are rarely used nowadays due to their low throughput. Modern standards such as IEEE 802.11 n/ac, and the upcoming 802.11 ax are much more relevant.

There are many improvements and differences introduced with the 802.11 n standard. One of the most important with respect to time-domain sample cross-correlation is the adoption of \gls{MIMO} transmission. With this technique, every sender and receiver uses multiple antennas, instead of just one as with 802.11 a/g. This allows for a much higher spectral efficiency, meaning that more bits can be transmitted per used bandwidth \cite{NEEDED}. However, the overall system complexity and multi-path effects in particular make it much more difficult to apply naive time-domain correlation.\\

It would be interesting whether the proposed sender detection algorithm can be adapted to work in a \gls{MIMO} environment. In the current form, this is unfortunately quite unlikely. On the one hand, collision detection and especially the determination of relevant sample periods containing the sender MAC addresses must be adjusted to the physical layer high-throughput frame format used by modern standards \cite{ieee2012}.

On the other hand, using multiple streams implies the possibility that the sender MAC address gets fragmented. While some bits could be transmitted in the first stream, the remaining bits could be sent in various other streams. This renders simple cross-correlation with \texttt{xcorr} directly on the received sample vector useless.


%% -----------------------------------------------------------------------------

\section{Future Work}
